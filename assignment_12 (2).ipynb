{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.What is a parameter?\n",
        "\n",
        "A parameter is a numerical value that describes a characteristic of an entire population. It is usually fixed but unknown and is estimated using sample data."
      ],
      "metadata": {
        "id": "30BnQlDSJM5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What is correlation?\n",
        "What does negative correlation mean?\n",
        "\n",
        "\n",
        "**What is correlation?**\n",
        "\n",
        "Correlation is a statistical measure that describes the strength and direction of the relationship between two variables.\n",
        "\n",
        "**What does negative correlation mean?**\n",
        "\n",
        "Negative correlation means that as one variable increases, the other variable decreases, and vice versa.\n",
        "\n"
      ],
      "metadata": {
        "id": "thpzzI0xJotS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "\n",
        "**Definition of Machine Learning:**\n",
        "Machine Learning is a branch of Artificial Intelligence that enables computers to learn from data and improve their performance without being explicitly programmed.\n",
        "\n",
        "**Main components of Machine Learning:**\n",
        "\n",
        "1. **Data** – The raw information used for training the model.\n",
        "2. **Algorithm** – The mathematical method used to learn patterns from data.\n",
        "3. **Model** – The trained representation that makes predictions or decisions.\n",
        "4. **Training process** – The procedure of feeding data to the algorithm to learn patterns.\n",
        "5. **Evaluation** – Measuring model performance using metrics like accuracy or error.\n",
        "\n"
      ],
      "metadata": {
        "id": "dkbLz0ShKD2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "The loss value measures how far the model’s predicted output is from the actual output. A lower loss value indicates that the model’s predictions are closer to the true values, meaning the model is performing well. A high loss value shows poor performance. By monitoring the loss during training and validation, we can determine whether the model is improving and whether it fits the data properly.\n"
      ],
      "metadata": {
        "id": "N8Qr1ZGcKfga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What are continuous and categorical variables?\n",
        "\n",
        "**Continuous Variables**\n",
        "\n",
        "Continuous variables are numerical variables that can take any value within a specific range. These values are obtained through measurement and can include decimals and fractions. Between any two continuous values, there are infinitely many possible values.\n",
        "\n",
        "In Machine Learning:\n",
        "Continuous variables are often used in regression problems and may require scaling or normalization.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Height of a person (165.5 cm)\n",
        "\n",
        "Weight (62.75 kg)\n",
        "\n",
        "**Categorical Variables**\n",
        "\n",
        "Categorical variables represent qualitative data that classify observations into distinct categories or groups. These variables do not have a numerical meaning even if numbers are used as labels.\n",
        "\n",
        "In Machine Learning:\n",
        "Categorical variables must be converted into numerical form using techniques like Label Encoding or One-Hot Encoding.\n",
        "\n"
      ],
      "metadata": {
        "id": "wpyDjgbiKyDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.How do we handle categorical variables in Machine Learning? What are the common t\n",
        "echniques?\n",
        "\n",
        "\n",
        "### Handling Categorical Variables in Machine Learning\n",
        "\n",
        "Categorical variables cannot be directly used in most Machine Learning algorithms because these algorithms work with numerical data. Therefore, categorical variables must be **converted into numerical form** before model training. This process is called **categorical encoding**.\n",
        "\n",
        "---\n",
        "\n",
        "### Common Techniques to Handle Categorical Variables\n",
        "\n",
        "#### 1. Label Encoding\n",
        "\n",
        "Label Encoding assigns a **unique numerical value** to each category.\n",
        "\n",
        "**Example:**\n",
        "Gender → Male = 0, Female = 1\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "* Simple and fast\n",
        "* Works well for **ordinal data**\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "* Can introduce false order for **nominal data**\n",
        "\n",
        "\n",
        "\n",
        "#### 2. One-Hot Encoding\n",
        "\n",
        "One-Hot Encoding creates **binary columns** for each category.\n",
        "\n",
        "**Example:**\n",
        "Color → Red, Blue, Green\n",
        "→ [1,0,0], [0,1,0], [0,0,1]\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "* No false ranking\n",
        "* Suitable for **nominal variables**\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "* Increases dimensionality when categories are many\n",
        "\n",
        "\n",
        "\n",
        "#### 3. Ordinal Encoding\n",
        "\n",
        "Used when categories have a **natural order**.\n",
        "\n",
        "**Example:**\n",
        "Low = 1, Medium = 2, High = 3\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "* Preserves order information\n",
        "* Easy to implement\n",
        "\n",
        "\n",
        "\n",
        "#### 4. Binary Encoding\n",
        "\n",
        "Categories are converted into **binary digits**.\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "* Reduces dimensionality compared to one-hot encoding\n",
        "* Efficient for high-cardinality features\n",
        "\n",
        "\n",
        "\n",
        "#### 5. Target Encoding (Mean Encoding)\n",
        "\n",
        "Categories are replaced by the **mean of the target variable** for each category.\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "* Useful for high-cardinality data\n",
        "* Can improve model performance\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "* Risk of overfitting if not handled carefully\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BrmmlfW9L8GI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What do you mean by training and testing a dataset?\n",
        "\n",
        "\n",
        "\n",
        "### Training and Testing of a Dataset\n",
        "\n",
        "In Machine Learning, a dataset is usually divided into two parts: **training data** and **testing data**. This process helps in building and evaluating the performance of a model.\n",
        "\n",
        "---\n",
        "\n",
        "### Training Dataset\n",
        "\n",
        "The **training dataset** is the portion of data used to **train the machine learning model**. The model learns patterns, relationships, and features from this data by adjusting its parameters to minimize error.\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "* To teach the model how to make predictions\n",
        "* To learn underlying patterns in the data\n",
        "\n",
        "---\n",
        "\n",
        "### Testing Dataset\n",
        "\n",
        "The **testing dataset** is the portion of data used to **evaluate the performance of the trained model**. This data is not shown to the model during training.\n",
        "\n",
        "**Purpose:**\n",
        "\n",
        "* To check how well the model performs on unseen data\n",
        "* To detect overfitting or underfitting\n",
        "\n"
      ],
      "metadata": {
        "id": "fGt4srFLMekS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "`sklearn.preprocessing` is a **module in the Scikit-learn library** used for **data preprocessing** in Machine Learning. It provides tools to **transform raw data into a suitable format** so that machine learning models can perform better.\n",
        "\n",
        "---\n",
        "\n",
        "### Purpose of `sklearn.preprocessing`\n",
        "\n",
        "* Scale numerical features\n",
        "* Encode categorical variables\n",
        "* Normalize and standardize data\n",
        "* Prepare data for training ML models\n",
        "\n",
        "---\n",
        "\n",
        "### Common Functions and Classes in `sklearn.preprocessing`\n",
        "\n",
        "1. **StandardScaler**\n",
        "\n",
        "   * Standardizes features to have mean = 0 and standard deviation = 1\n",
        "\n",
        "2. **MinMaxScaler**\n",
        "\n",
        "   * Scales features to a fixed range (usually 0 to 1)\n",
        "\n",
        "3. **Normalizer**\n",
        "\n",
        "   * Normalizes samples to unit norm\n",
        "\n",
        "4. **LabelEncoder**\n",
        "\n",
        "   * Converts categorical labels into numerical form\n",
        "\n",
        "5. **OneHotEncoder**\n",
        "\n",
        "   * Converts categorical features into binary vectors\n",
        "\n",
        "6. **Binarizer**\n",
        "\n",
        "   * Converts numerical values into binary (0 or 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZmLzyR9EM6Po"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is a Test set?\n",
        "\n",
        "\n",
        "**Test Set:**\n",
        "A **test set** is a portion of the dataset that is used to **evaluate the performance of a trained machine learning model**. It contains data that the model has **never seen during training**, so it helps measure how well the model generalizes to new, unseen data.\n",
        "\n",
        "**Purpose of a Test Set:**\n",
        "\n",
        "* To assess model accuracy and performance\n",
        "* To detect overfitting or underfitting\n",
        "* To check real-world prediction ability\n",
        "\n",
        "**Example:**\n",
        "If a dataset is split into 80% training data and 20% test data, the 20% portion is called the **test set**.\n",
        "\n"
      ],
      "metadata": {
        "id": "4FFV0JhYNUo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "\n",
        "In Python, data is commonly split into **training** and **testing** sets using the **`train_test_split()`** function from the `sklearn.model_selection` module.\n",
        "\n",
        "### Steps:\n",
        "\n",
        "1. Import the required function\n",
        "2. Separate features (X) and target variable (y)\n",
        "3. Split the data into training and testing sets\n",
        "\n",
        "### Example:\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "* `X_train`, `y_train` → used to train the model\n",
        "* `X_test`, `y_test` → used to test the model\n",
        "* `test_size=0.2` → 20% data for testing, 80% for training\n",
        "* `random_state` → ensures reproducibility\n",
        "\n",
        "### Purpose:\n",
        "\n",
        "* To evaluate model performance on unseen data\n",
        "* To avoid overfitting\n",
        "\n",
        "---\n",
        "\n",
        " 2. How do you approach a Machine Learning problem?\n",
        "\n",
        "A Machine Learning problem is approached through a **systematic step-by-step process**:\n",
        "\n",
        "### Steps to Approach a Machine Learning Problem:\n",
        "\n",
        "1. **Understand the Problem**\n",
        "\n",
        "   * Identify the goal (classification, regression, clustering, etc.)\n",
        "\n",
        "2. **Collect Data**\n",
        "\n",
        "   * Gather relevant and sufficient data from reliable sources\n",
        "\n",
        "3. **Explore the Data (EDA)**\n",
        "\n",
        "   * Analyze data structure, patterns, missing values, and outliers\n",
        "\n",
        "4. **Data Preprocessing**\n",
        "\n",
        "   * Handle missing values\n",
        "   * Encode categorical variables\n",
        "   * Scale or normalize data\n",
        "\n",
        "5. **Split the Data**\n",
        "\n",
        "   * Divide data into training and testing sets\n",
        "\n",
        "6. **Choose a Model**\n",
        "\n",
        "   * Select an appropriate ML algorithm based on the problem\n",
        "\n",
        "7. **Train the Model**\n",
        "\n",
        "   * Fit the model using training data\n",
        "\n",
        "8. **Evaluate the Model**\n",
        "\n",
        "   * Use metrics like accuracy, precision, recall, RMSE, etc.\n",
        "\n",
        "9. **Tune the Model**\n",
        "\n",
        "   * Optimize hyperparameters to improve performance\n",
        "\n",
        "10. **Deploy the Model**\n",
        "\n",
        "* Use the trained model for real-world predictions\n"
      ],
      "metadata": {
        "id": "IN5WRmkXNlQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "\n",
        "\n",
        "**Exploratory Data Analysis (EDA)** is performed before fitting a machine learning model to **understand the data better** and ensure that it is suitable for modeling. EDA helps identify patterns, issues, and relationships in the dataset that can directly affect model performance.\n",
        "\n",
        "---\n",
        "\n",
        "### Importance of EDA before Model Fitting\n",
        "\n",
        "1. **Understanding Data Structure**\n",
        "   EDA helps in understanding the number of features, data types (numerical or categorical), and the overall structure of the dataset.\n",
        "\n",
        "2. **Detecting Missing Values**\n",
        "   It identifies missing or null values so that appropriate methods like imputation or removal can be applied.\n",
        "\n",
        "3. **Identifying Outliers**\n",
        "   EDA helps detect extreme values that may negatively impact the model and need to be handled.\n",
        "\n",
        "4. **Understanding Feature Relationships**\n",
        "   Correlation analysis and visualizations help identify relationships between variables and the target feature.\n",
        "\n",
        "5. **Checking Data Distribution**\n",
        "   It helps determine whether data is normally distributed or skewed, which guides feature transformation and scaling.\n",
        "\n",
        "6. **Feature Selection and Engineering**\n",
        "   EDA helps identify irrelevant or redundant features and suggests useful feature transformations.\n",
        "\n",
        "7. **Reducing Model Errors**\n",
        "   By addressing data issues early, EDA reduces the chances of underfitting or overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "yvO9wsBnOOhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.What is correlation?\n",
        "\n",
        "Correlation is a statistical measure that shows the degree (strength) and direction of the relationship between two variables. It explains how one variable changes in relation to another.\n",
        "\n",
        "For example, if the value of one variable increases and the other variable also increases, the variables are said to be positively correlated.\n",
        "\n",
        "\n",
        "Correlation Coefficient\n",
        "\n",
        "The strength and direction of correlation are measured using a correlation coefficient (r).\n",
        "\n",
        "Value of r ranges from -1 to +1\n",
        "\n",
        "r = +1 → Perfect positive correlation\n",
        "\n",
        "r = -1 → Perfect negative correlation\n",
        "\n",
        "r = 0 → No correlation\n",
        "\n",
        "Importance of Correlation\n",
        "\n",
        "Helps understand relationships between variables\n",
        "\n",
        "Useful in feature selection in Machine Learning\n",
        "\n",
        "Assists in prediction and data analysis\n",
        "\n",
        "Used in statistics, economics, and data science"
      ],
      "metadata": {
        "id": "reeGf83BOyVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.What does negative correlation mean?\n",
        "\n",
        "Negative correlation means that two variables move in opposite directions. When the value of one variable increases, the value of the other variable decreases, and when one decreases, the other increases.\n",
        "\n",
        "Explanation with Example\n",
        "\n",
        "As speed of a vehicle increases, the time taken to reach a destination decreases.\n",
        "\n",
        "As price of a product increases, demand usually decreases.\n",
        "\n",
        "These pairs of variables show negative correlation because they change in opposite directions.\n",
        "\n",
        "\n",
        "Correlation Coefficient in Negative Correlation\n",
        "\n",
        "The correlation coefficient (r) is less than 0\n",
        "\n",
        "Range: –1 < r < 0\n",
        "\n",
        "r = –1 → Perfect negative correlation\n",
        "\n",
        "r close to 0 → Weak negative correlation\n",
        "\n"
      ],
      "metadata": {
        "id": "3Ssih3o1Pb-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.How can you find correlation between variables in Python?\n",
        "\n",
        "\n",
        "### Finding Correlation Between Variables in Python\n",
        "\n",
        "In Python, we commonly use **Pandas** or **NumPy** to calculate correlation between variables.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Using Pandas `corr()` Method\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {'Height': [150, 160, 170, 180, 190],\n",
        "        'Weight': [50, 60, 65, 70, 80]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "  * +1 → Perfect positive correlation\n",
        "  * –1 → Perfect negative correlation\n",
        "  * 0 → No correlation\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Using NumPy `corrcoef()` Function\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "height = [150, 160, 170, 180, 190]\n",
        "weight = [50, 60, 65, 70, 80]\n",
        "\n",
        "correlation = np.corrcoef(height, weight)\n",
        "print(correlation)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "\n",
        "```\n",
        "[[1.   0.99]\n",
        " [0.99 1.  ]]\n",
        "```\n",
        "\n",
        "* Returns a **correlation matrix** similar to Pandas.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Using Seaborn for Visualization\n",
        "\n",
        "```python\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "* Visualizes correlations in a **heatmap** for easy understanding.\n",
        "* Darker or lighter colors indicate **stronger correlations**.\n",
        "\n"
      ],
      "metadata": {
        "id": "wIHqeiSRP9pS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {'Height': [150, 160, 170, 180, 190],\n",
        "        'Weight': [50, 60, 65, 70, 80]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-CPcjagREuO",
        "outputId": "4995ce5e-a885-425f-a086-5c5d2c5ff772"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Height    Weight\n",
            "Height  1.000000  0.989949\n",
            "Weight  0.989949  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "height = [150, 160, 170, 180, 190]\n",
        "weight = [50, 60, 65, 70, 80]\n",
        "\n",
        "correlation = np.corrcoef(height, weight)\n",
        "print(correlation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbEA-yI9RQHi",
        "outputId": "eb59321d-b63e-476b-da88-9ea1e096a54f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.98994949]\n",
            " [0.98994949 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "mtb6AHkTRXRO",
        "outputId": "bc9ecd71-5668-4cbf-ef8a-48d75d710990"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "\n",
        "### What is Causation?\n",
        "\n",
        "**Causation** (or causal relationship) means that **one event or variable directly causes a change in another**. In other words, a change in the cause variable leads to a change in the effect variable.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "* Smoking → Lung cancer\n",
        "  Smoking directly increases the risk of lung cancer. Here, smoking **causes** lung cancer.\n",
        "\n",
        "---\n",
        "\n",
        "### Difference Between Correlation and Causation\n",
        "\n",
        "| Feature     | Correlation                                                        | Causation                                                  |\n",
        "| ----------- | ------------------------------------------------------------------ | ---------------------------------------------------------- |\n",
        "| Meaning     | Measures the **relationship or association** between two variables | Indicates that **one variable directly affects** the other |\n",
        "| Direction   | Can be positive, negative, or zero                                 | Always indicates a directional effect (cause → effect)     |\n",
        "| Implication | Does **not imply one causes the other**                            | Shows a **direct cause-effect relationship**               |\n",
        "| Example     | Ice cream sales ↑ ↔ Drowning incidents ↑ (both rise in summer)     | Smoking ↑ → Lung cancer ↑                                  |\n",
        "\n"
      ],
      "metadata": {
        "id": "rALhSW4nRnKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "\n",
        "### What is an Optimizer?\n",
        "\n",
        "In **Machine Learning and Deep Learning**, an **optimizer** is an algorithm or method used to **update the model’s parameters (weights and biases) during training** in order to **minimize the loss function**. The goal is to make the model predictions as close as possible to the actual values.\n",
        "\n",
        "\n",
        "### Types of Optimizers\n",
        "\n",
        "#### 1. **Gradient Descent (GD)**\n",
        "\n",
        "* Updates weights in the **opposite direction of the gradient** of the loss function.\n",
        "* **Types:**\n",
        "\n",
        "  * **Batch Gradient Descent**: Uses the entire dataset for one update.\n",
        "  * **Stochastic Gradient Descent (SGD)**: Uses one sample at a time.\n",
        "  * **Mini-batch Gradient Descent**: Uses a small batch of data for each update.\n",
        "\n",
        "**Example:**\n",
        "Training a linear regression model using SGD updates weights after each training sample.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **Momentum**\n",
        "\n",
        "* Accelerates gradient descent by **adding a fraction of the previous update** to the current update.\n",
        "* Helps in **faster convergence** and reduces oscillations.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "```\n",
        "v = β*v_prev + (1-β)*gradient\n",
        "weight = weight - learning_rate*v\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "Used in training deep neural networks where learning is slow or oscillatory.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **RMSProp (Root Mean Square Propagation)**\n",
        "\n",
        "* Adapts the learning rate for each parameter individually.\n",
        "* Maintains a **moving average of squared gradients** to normalize updates.\n",
        "* Helps when gradients are **sparse or uneven**.\n",
        "\n",
        "**Example:**\n",
        "Used in Recurrent Neural Networks (RNNs) to stabilize learning.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. **Adam (Adaptive Moment Estimation)**\n",
        "\n",
        "* Combines **Momentum** and **RMSProp**.\n",
        "* Maintains moving averages of **both gradients and squared gradients**.\n",
        "* Widely used because it adapts learning rates and converges quickly.\n",
        "\n",
        "**Example:**\n",
        "Most commonly used in training Convolutional Neural Networks (CNNs) for image recognition.\n",
        "\n",
        "---\n",
        "\n",
        "#### 5. **Adagrad**\n",
        "\n",
        "* Adapts the learning rate for each parameter based on how frequently it is updated.\n",
        "* Parameters updated less frequently get **larger updates**.\n",
        "\n",
        "**Example:**\n",
        "Used in natural language processing where some words appear rarely.\n"
      ],
      "metadata": {
        "id": "3WUcTHyjSRs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.What is sklearn.linear_model ?\n",
        "\n",
        "\n",
        "\n",
        "`sklearn.linear_model` is a **module in the Scikit-learn library** that provides classes and functions for **linear models** in Machine Learning. Linear models are used to predict a **continuous or categorical target variable** based on one or more features by fitting a **linear equation** to the observed data.\n",
        "\n",
        "\n",
        "\n",
        "### Purpose\n",
        "\n",
        "* To perform **regression** (predict numerical values)\n",
        "* To perform **classification** (predict categorical outcomes) using linear methods\n",
        "* To provide **easy-to-use, efficient implementations** of standard linear algorithms\n",
        "\n",
        "\n",
        "\n",
        "### Common Classes in `sklearn.linear_model`\n",
        "\n",
        "1. **LinearRegression**\n",
        "\n",
        "   * Performs **simple or multiple linear regression**\n",
        "   * Predicts a continuous target variable based on one or more input features\n",
        "   * **Example:** Predicting house prices based on area, bedrooms, and location\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "```\n",
        "\n",
        "2. **LogisticRegression**\n",
        "\n",
        "   * Performs **classification** using a logistic function\n",
        "   * Predicts **binary or multiclass outcomes**\n",
        "   * **Example:** Predicting if a student passes or fails based on study hours and attendance\n",
        "\n",
        "3. **Ridge**\n",
        "\n",
        "   * Linear regression with **L2 regularization**\n",
        "   * Helps prevent overfitting by penalizing large coefficients\n",
        "\n",
        "4. **Lasso**\n",
        "\n",
        "   * Linear regression with **L1 regularization**\n",
        "   * Can **shrink some coefficients to zero**, useful for feature selection\n",
        "\n",
        "5. **ElasticNet**\n",
        "\n",
        "   * Combines **L1 and L2 regularization**\n",
        "   * Balances feature selection and coefficient shrinkage\n",
        "\n",
        "---\n",
        "\n",
        "### Advantages\n",
        "\n",
        "* Easy to implement and interpret\n",
        "* Works well with **linearly separable data**\n",
        "* Supports **regularization** to prevent overfitting\n"
      ],
      "metadata": {
        "id": "8d8JEJ6yS-wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.What does model.fit() do? What arguments must be given?\n",
        "\n",
        "\n",
        "In **Scikit-learn**, the method `model.fit()` is used to **train a machine learning model** on the given dataset. During this process, the model **learns the relationship between input features (X) and the target variable (y)** by adjusting its internal parameters (like weights in linear regression or neural networks) to minimize the error or loss.\n",
        "\n",
        "\n",
        "\n",
        "### Arguments Required for `model.fit()`\n",
        "\n",
        "1. **X** – Features or independent variables\n",
        "\n",
        "   * A 2D array or DataFrame containing input data.\n",
        "   * Shape: `(n_samples, n_features)`\n",
        "\n",
        "2. **y** – Target or dependent variable\n",
        "\n",
        "   * A 1D or 2D array containing the output labels or values.\n",
        "   * Shape: `(n_samples,)` for single-output tasks\n",
        "\n",
        "**Optional arguments** (depending on the model):\n",
        "\n",
        "* `sample_weight` – To assign different importance to different samples\n",
        "* `epochs`, `batch_size` – In deep learning models\n",
        "\n",
        "---\n",
        "\n",
        "### Example with Linear Regression\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Features (X) and target (y)\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# The model has now learned the relationship between X and y\n",
        "```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "* After `model.fit(X, y)`, the model learns the **best-fit line** (y = mx + c) that predicts `y` from `X`.\n",
        "\n"
      ],
      "metadata": {
        "id": "KeIQZK1LTuq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Features (X) and target (y)\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "yIhemE8tUVPW",
        "outputId": "03cecc8b-8e92-4452-dff2-aad6907e589e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.What does model.predict() do? What arguments must be given?\n",
        "\n",
        "\n",
        "In **Scikit-learn**, the method `model.predict()` is used to **make predictions using a trained machine learning model**. After the model has been trained with `model.fit()`, it uses the learned relationship between features and target to **predict the output** for new or unseen data.\n",
        "\n",
        "---\n",
        "\n",
        "### Arguments Required for `model.predict()`\n",
        "\n",
        "1. **X** – Features or independent variables for which you want predictions\n",
        "\n",
        "   * A 2D array or DataFrame containing input data.\n",
        "   * Shape: `(n_samples, n_features)`\n",
        "\n",
        "**Example with Linear Regression**\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Training data\n",
        "X_train = [[1], [2], [3], [4], [5]]\n",
        "y_train = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Create and train model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# New data for prediction\n",
        "X_new = [[6], [7]]\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_new)\n",
        "print(predictions)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M_PreTBsUX5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Training data\n",
        "X_train = [[1], [2], [3], [4], [5]]\n",
        "y_train = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Create and train model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# New data for prediction\n",
        "X_new = [[6], [7]]\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_new)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_K0E-nDU9-J",
        "outputId": "a11b018e-f57f-491d-b868-9c39bc9bb3f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12. 14.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "\n",
        "### Continuous Variables\n",
        "\n",
        "**Continuous variables** are **numerical variables** that can take **any value within a range**. They are measured rather than counted and can include decimals or fractions.\n",
        "\n",
        "**Characteristics:**\n",
        "\n",
        "* Quantitative (numeric)\n",
        "* Infinite possible values within a range\n",
        "* Arithmetic operations like addition and averaging are meaningful\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* Height of a person (e.g., 165.5 cm)\n",
        "* Weight (e.g., 62.3 kg)\n",
        "* Temperature (e.g., 36.6°C)\n",
        "* Time taken to complete a task\n",
        "\n",
        "**Use in Machine Learning:**\n",
        "\n",
        "* Often used in **regression problems**\n",
        "* May require **scaling or normalization**\n",
        "\n",
        "---\n",
        "\n",
        "### Categorical Variables\n",
        "\n",
        "**Categorical variables** represent **qualitative data** that classify observations into **distinct categories**. They do not have inherent numeric meaning.\n",
        "\n",
        "**Characteristics:**\n",
        "\n",
        "* Qualitative (non-numeric)\n",
        "* Finite set of categories\n",
        "* Cannot be directly measured; can only be counted\n",
        "* Arithmetic operations are not meaningful\n",
        "\n",
        "**Types of Categorical Variables:**\n",
        "\n",
        "1. **Nominal:** No order among categories\n",
        "\n",
        "   * Example: Gender (Male, Female), Color (Red, Blue, Green)\n",
        "2. **Ordinal:** Categories with a defined order\n",
        "\n",
        "   * Example: Education level (High School < Bachelor < Master < PhD)\n",
        "\n",
        "**Use in Machine Learning:**\n",
        "\n",
        "* Must be **encoded numerically** before using in most algorithms (e.g., Label Encoding, One-Hot Encoding)\n",
        "\n",
        "---\n",
        "\n",
        "### Key Difference\n",
        "\n",
        "| Feature  | Continuous            | Categorical                      |\n",
        "| -------- | --------------------- | -------------------------------- |\n",
        "| Type     | Numeric               | Qualitative                      |\n",
        "| Values   | Infinite within range | Finite categories                |\n",
        "| Examples | Height, Weight        | Gender, Color                    |\n",
        "| ML Use   | Regression models     | Classification or encoded for ML |\n"
      ],
      "metadata": {
        "id": "bNlbxChIVgp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "**Feature scaling** is a **technique used to standardize the range of independent variables (features) in a dataset**. It ensures that all features contribute equally to the learning process by **bringing them to a similar scale**, usually between 0–1 or with zero mean and unit variance.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Feature Scaling is Important in Machine Learning\n",
        "\n",
        "Many Machine Learning algorithms, especially **distance-based** or **gradient-based** methods, are sensitive to the scale of features. Feature scaling helps in:\n",
        "\n",
        "1. **Faster Convergence in Gradient Descent**\n",
        "\n",
        "   * Features on similar scales help the optimizer converge faster.\n",
        "\n",
        "2. **Preventing Dominance of Large-Scale Features**\n",
        "\n",
        "   * Without scaling, features with larger numerical ranges can dominate the learning process.\n",
        "\n",
        "3. **Improved Model Accuracy**\n",
        "\n",
        "   * Ensures that all features contribute proportionately.\n",
        "\n",
        "4. **Better Performance in Distance-Based Algorithms**\n",
        "\n",
        "   * Algorithms like **K-Nearest Neighbors, SVM, and K-Means** rely on distance measures; scaling prevents bias toward larger features.\n",
        "\n",
        "---\n",
        "\n",
        "### Common Feature Scaling Techniques\n",
        "\n",
        "1. **Min-Max Normalization**\n",
        "\n",
        "   * Scales values to a fixed range (usually 0–1)\n",
        "   * Formula:\n",
        "     [\n",
        "     X_{\\text{scaled}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}\n",
        "     ]\n",
        "\n",
        "2. **Standardization (Z-score Normalization)**\n",
        "\n",
        "   * Scales features to have **zero mean** and **unit variance**\n",
        "   * Formula:\n",
        "     [\n",
        "     X_{\\text{scaled}} = \\frac{X - \\mu}{\\sigma}\n",
        "     ]\n",
        "     where μ = mean, σ = standard deviation\n",
        "\n",
        "3. **Robust Scaling**\n",
        "\n",
        "   * Uses **median and interquartile range** to scale features, reducing the effect of outliers\n",
        "\n",
        "---\n",
        "\n",
        "### Example in Python\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # X is the feature matrix\n",
        "```\n"
      ],
      "metadata": {
        "id": "tRfzcp1uV7XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # X is the feature matrix"
      ],
      "metadata": {
        "id": "fOMKovs9WVTu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.How do we perform scaling in Python?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In Python, feature scaling is commonly done using the **`sklearn.preprocessing`** module. The most frequently used techniques are **Standardization** and **Min-Max Normalization**.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Standardization (Z-score Scaling)\n",
        "\n",
        "Scales features to have **zero mean** and **unit variance**.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Example feature matrix\n",
        "X = np.array([[10, 200],\n",
        "              [20, 300],\n",
        "              [30, 400]])\n",
        "\n",
        "# Create scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Min-Max Scaling (Normalization)\n",
        "\n",
        "Scales features to a fixed range, usually **0 to 1**.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Other Scaling Techniques\n",
        "\n",
        "* **RobustScaler** – Uses median and interquartile range; less sensitive to outliers\n",
        "* **Normalizer** – Scales each sample to have unit norm (often used in text data)\n",
        "\n",
        "---\n",
        "\n",
        "### Steps to Perform Scaling\n",
        "\n",
        "1. **Import the scaler** from `sklearn.preprocessing`\n",
        "2. **Create an instance** of the scaler\n",
        "3. **Fit and transform** the feature matrix using `fit_transform()`\n",
        "4. **Use `transform()`** on test data (without fitting) to avoid data leakage\n",
        "\n",
        "```python\n",
        "# For test data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "```\n"
      ],
      "metadata": {
        "id": "jvWx-dqrWcMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Standardization (Z-score Scaling)\n"
      ],
      "metadata": {
        "id": "K4RvhCHJWbms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Example feature matrix\n",
        "X = np.array([[10, 200],\n",
        "              [20, 300],\n",
        "              [30, 400]])\n",
        "\n",
        "# Create scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J77yQ09xW_Bn",
        "outputId": "0f98ce1f-e0d5-4c46-a2d4-fcf6f66639ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Min-Max Scaling (Normalization)"
      ],
      "metadata": {
        "id": "tOMMB9V7WbH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysKcSpiwXQ-g",
        "outputId": "1fd5d3ba-3848-4885-f675-98cb57c45307"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.What is sklearn.preprocessing?\n",
        "\n",
        "`sklearn.preprocessing` is a **module in the Scikit-learn library** that provides tools for **preprocessing and transforming data** before applying machine learning algorithms. It includes functions and classes to **scale, normalize, and encode data**, making it suitable for training models.\n",
        "\n",
        "---\n",
        "\n",
        "### Purpose of `sklearn.preprocessing`\n",
        "\n",
        "* **Scale numerical features** to a standard range\n",
        "* **Normalize data** for consistent magnitude\n",
        "* **Encode categorical variables** into numerical form\n",
        "* **Prepare data** for training machine learning models efficiently\n",
        "\n",
        "---\n",
        "\n",
        "### Common Classes and Functions\n",
        "\n",
        "1. **StandardScaler**\n",
        "\n",
        "   * Standardizes features to have **mean = 0** and **standard deviation = 1**\n",
        "   * Useful for gradient-based algorithms\n",
        "\n",
        "2. **MinMaxScaler**\n",
        "\n",
        "   * Scales features to a **fixed range**, usually 0–1\n",
        "   * Useful when features have different scales\n",
        "\n",
        "3. **Normalizer**\n",
        "\n",
        "   * Normalizes each sample to have **unit norm**\n",
        "\n",
        "4. **LabelEncoder**\n",
        "\n",
        "   * Converts categorical labels into **numeric form**\n",
        "\n",
        "5. **OneHotEncoder**\n",
        "\n",
        "   * Converts categorical features into **binary vectors**\n",
        "\n",
        "6. **Binarizer**\n",
        "\n",
        "   * Converts numerical values into **0 or 1** based on a threshold\n",
        "\n",
        "---\n",
        "\n",
        "### Example in Python\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # X is the feature matrix\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Why It’s Important\n",
        "\n",
        "* Many ML algorithms are **sensitive to feature scale**\n",
        "* Proper preprocessing improves **model accuracy and training speed**\n",
        "* Makes data **uniform and ready** for algorithms\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PlOIQFZfXzGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "\n",
        "In machine learning, a dataset is usually split into **training** and **testing** sets:\n",
        "\n",
        "* **Training set:** Used to train the model\n",
        "* **Testing set:** Used to evaluate the model on unseen data\n",
        "\n",
        "This ensures that the model **generalizes well** and does not just memorize the training data.\n",
        "\n",
        "---\n",
        "\n",
        "### Using `train_test_split()` from Scikit-learn\n",
        "\n",
        "Python provides the `train_test_split()` function in the `sklearn.model_selection` module to split data easily.\n",
        "\n",
        "---\n",
        "\n",
        "### Example:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Split data: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"X_train:\", X_train)\n",
        "print(\"X_test:\", X_test)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "* `X_train`, `y_train` → Data used to **train the model**\n",
        "* `X_test`, `y_test` → Data used to **evaluate the model**\n",
        "* `test_size=0.2` → 20% of data for testing\n",
        "* `random_state=42` → Ensures reproducibility\n",
        "\n",
        "---\n",
        "\n",
        "### Why Split Data?\n",
        "\n",
        "1. To **evaluate model performance** on unseen data\n",
        "2. To **prevent overfitting**\n",
        "3. To **assess generalization ability** of the model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c96-GdwbYzX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = [[1], [2], [3], [4], [5]]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "# Split data: 80% training, 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"X_train:\", X_train)\n",
        "print(\"X_test:\", X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXH-Sxp4ZTVd",
        "outputId": "05bf0f4f-62e9-403b-fdc4-90e0a9bb6077"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: [[5], [3], [1], [4]]\n",
            "X_test: [[2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Explain data encoding?\n",
        "\n",
        "\n",
        "\n",
        "### What is Data Encoding?\n",
        "\n",
        "**Data encoding** is the process of **converting categorical (non-numeric) data into numerical form** so that it can be used by machine learning algorithms. Most ML algorithms can only process **numerical inputs**, so encoding is essential when working with **categorical features**.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Data Encoding is Important\n",
        "\n",
        "* Machine learning models require **numerical input**\n",
        "* Helps algorithms understand **categorical relationships**\n",
        "* Prevents errors while training the model\n",
        "\n",
        "---\n",
        "\n",
        "### Common Types of Data Encoding\n",
        "\n",
        "#### 1. **Label Encoding**\n",
        "\n",
        "* Assigns a **unique integer** to each category\n",
        "* Suitable for **ordinal data** where order matters\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```\n",
        "Color → Red, Blue, Green\n",
        "Encoded → Red=0, Blue=1, Green=2\n",
        "```\n",
        "\n",
        "**Python Example:**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(['Red', 'Blue', 'Green', 'Red'])\n",
        "print(y_encoded)  # Output: [2 0 1 2]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **One-Hot Encoding**\n",
        "\n",
        "* Converts categorical variables into **binary columns**\n",
        "* Suitable for **nominal data** (no order)\n",
        "* Avoids introducing false ordering\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```\n",
        "Color → Red, Blue, Green\n",
        "One-Hot → Red=[1,0,0], Blue=[0,1,0], Green=[0,0,1]\n",
        "```\n",
        "\n",
        "**Python Example:**\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(['Red','Blue','Green']).reshape(-1,1)\n",
        "ohe = OneHotEncoder()\n",
        "X_encoded = ohe.fit_transform(X).toarray()\n",
        "print(X_encoded)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **Ordinal Encoding**\n",
        "\n",
        "* Used when **categories have a natural order**\n",
        "* Similar to Label Encoding but preserves **ranking**\n",
        "\n",
        "**Example:**\n",
        "Education → High School=1, Bachelor=2, Master=3, PhD=4\n",
        "\n"
      ],
      "metadata": {
        "id": "u0SiXv_QZdye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(['Red', 'Blue', 'Green', 'Red'])\n",
        "print(y_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6OUlbOQZ4Rm",
        "outputId": "61c72bb6-89e7-4ffa-f39b-e0a2c72d9634"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "X = np.array(['Red','Blue','Green']).reshape(-1,1)\n",
        "ohe = OneHotEncoder()\n",
        "X_encoded = ohe.fit_transform(X).toarray()\n",
        "print(X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ2Z4KMfaE_G",
        "outputId": "a8059b5a-7763-40a9-af5f-e92c6f8f75f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]]\n"
          ]
        }
      ]
    }
  ]
}